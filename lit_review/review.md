## #. Revisión de Literatura

### #.1. Potencial de ChatGPT en el Desarrollo de Software

- Abu Jaber, Beganovic y Abd Almisreb (2023):

The authors conduct a literature review on the potential of ChatGPT in software development. They outline potential uses for troubleshooting and bug repair, as well as educational applications for these purposes. This includes optimizing programs and numerical algorithms, as well as the potential incorporation of ChatGPT as an integrated controller in Generalized Intelligence. The authors discuss the creation of software solutions and architectures, both comparatively (evaluating multiple responses) and through a dialogical process with the application for software architectural design. They also delve into considerations for Prompt Engineering when employing the program for software development.

- Rahmaniar (2023):

This article discuses the potential for productivity gains in the field of software development through assistance in programming, documentation creation, training and onboarding, code review, and interactions with clients and stakeholders. All this thanks to the model's ability to process natural language, generative capacity, flexibility and potential for model learning, dialogical interactivity, the large spectrum of applicability for its use, and contributions to the Open Source space. However, it is necessary to consider negative ramifications, such as possible incompleteness of generated code, which may cause difficulties for users and potential security vulnerabilities. In this regard, there is also the potential for malicious use of the model to create malware. Ethical considerations must be taken into account, especially since, during the learning process, models may be exposed to content that integrates and perpetuates biases with negative consequences. With future improvements in language models, especially with the potential of GPT models, response generation would have better performance, translating into greater ease and productivity gains for developers using LLM tools. Future versions could be used for streamlining in the development process, where generation is constant with the aim of optimizing and repairing code in real time.

### #.2 ChatGPT puesto a prueba:

- Ahmad, Waseem, Liang, Fehmideh, Aktar & Mikkonen (2023):

This paper describes and tests human-bot collaboration for the purpose of formally outlining sofware architecture. Their testing starts with outlining an architecture story that describes the conditions that must be satisfied by the software. This outline is fed to the chatbot as an initial prompt as a preliminary step for the testing. After this, a novice software architect enters a dialectical process with the chatbot to analyze, synthesize, and evaluate a potential architectural solution.

- Sobania, Hanna, Briesch & Petke (2023):

The authors use the QuickBugs database, a repository of examples of buggy code, to test ChatGPT's code repair capabilities. They compare ChatGPT to two other LLMs specialized in code repair (Codex and CoCoNut) and a standard Automated Program Repair (APR) Neural Network program. ChatGPT's performance was comparable to that of the other LLMs (close to 50% of the buggy programs were repaired) and noticeably better than the standard APR when the test involved only one query in the dialogue. When the dialogue involves several queries, some of them used for clarification, the rate of success increased to 78%. One possible threat to the validity of this article is mentioned by Zhang et al. (2023): It is likely that the QuickBugs database was used for training the GPT model, and therefor the its output reflects the its fitness with the training sample and not the model's generalization capabilities.

- Zhang, Zhang, Zhai, Fang, Yu, Sun & Chen (2023):

This is another test to ChatGPT's buggy code repair capabilities. To contend with the previously mentioned criticism of Sobania et al. (2023)'s data, they construct a new databse called EvalGPTFix, built upon programming contest problems hosted in AtCode. The contents of EvalGPTFix consist of a correct answer and an incorrect answer for each programming problem, the latter of which is used as the buggy code to be repaired by ChatGPT. As all data used for training ChatGPT predates September 2021 and EvalGPTFix exclusively contains problems created after this date, the testing should specifically reveal the model's generalization capabilities.

### #.3 Impacto de ChatGPT en Desarrollo de Software

- Gallea (2023):

The author compares the Stack Overflow pages for Python and R, both programming languages used in data science. The reason behind this comparison is the fact that Python is a much more popular programming language with a high amount of potential training material for the model, and the author mentions the use of ChatGPT was not efficient when answer R related question; this would imply a lower impact of ChatGPT on the R language. The data comes from Stack Overflow Explorer, specifically information on the number of questions, the resolution status of the questions, and the score for each of them. The results from the Differences in Differences analysis suggest a negative impact on the quantity of questions, a positive impact on the average score (as a measure of quality) of questions, and a negative impact on the proportion of resolved questions (as a measure of complexity) for Python compared to R.

- Saguu & Ante (2023):

The authors analyze the returns of crypto-assets related to artificial intelligence. For this purpose, they utilize daily frequency data of crypto-asset prices from Coingecko and CoinMarketCap. The treatment group is considered as those assets related to artificial intelligence, and the start of the post-treatment period is the launch of ChatGPT. They also control for total market capitalization and transaction volume for each asset. They employ both the Differences in Differences and Synthetic Differences in Differences methods. They find that the launch of ChatGPT had a positive impact on the return of those assets related to artificial intelligence on both platforms, compared to those unrelated to AI.

- Demirci, Hannane & Xinrong (2023):

The authors analyze the impact of ChatGPT on the demand for services for freelance workers on a platform dedicated to facilitating such services. Firstly, they identify service groups based on the skills required to carry them out. Next, they assign an artificial intelligence exposure index to each type of service, indicating the feasibility of using AI to perform services in each group. The analysis is further adjusted using the Google Search Volume Index. They apply the Differences in Differences method between two groups: high and low exposure to artificial intelligence. They find that the impact of ChatGPT was negative on the quantity of postings seeking services in groups with high exposure to AI, compared to those with a low exposure index.

- Del Rio-Chanona, Laurentsyeva & Wachs (2023):

Este es otro ejemplo de análisis del impacto de ChatGPT en las plataformas de preguntas y respuestas para temas de programación. En este caso, los autores compara Stack Overflow con Math Exchange, una plataforma centrada en preguntas y respuestas sobre matemáticas; los temas de esta plataforma serían menos susceptibles a los efectos de ChatGPT. También comparan Stack Overflow con su contraparte rusa y con Segmentdefault, su contraparte china; el acceso a ChatGPT es restringido en estos dos países. Al aplicar Diferencias en Diferencias, los autores encuentran un impacto negativo en el número de posts por semana, número de preguntas por semana, y el número de posts en días de semana, en Stack Overflow en comparación con las demás plataformas.

This is another example of an analysis of the impact of ChatGPT on question and answer platforms for programming topics. In this case, the authors compare Stack Overflow with Math Exchange, a platform focused on questions and answers about mathematics; the topics on this platform would be less susceptible to the effects of ChatGPT. They also compare Stack Overflow with its Russian counterpart; and with Segmentdefault, its Chinese counterpart. This is because access to ChatGPT is restricted in these two countries, which would decrease the impact it can have on the software developmnet field. By applying Differences in Differences, the authors find a negative impact on the number of posts per week, the number of questions per week, and the number of posts on weekdays on Stack Overflow compared to the other platforms.

- Kreitmeir & Raschky (2023):

Finalmente, los autores analizan el impacto en la productividad en el desarrollo de software por medio de datos de frecuencia diaria al nivel de usuario provistos por GitHub. Explotan la prohibición de ChatGPT en Italia, país al cual comparan con Francia y Austria. Como medidas de productividad, los autores utilizan la existencia de nuevos lanzamientos por parte de cada usuario; la suma de push, pull-requests, comentarios en pull-requests, comentarios en commit, create e issues; suma de pushes y pulls; número de eventos totales por usuario. También analizan la cantidad de de Tor nuevos, pues por este medio los usuarios en países donde el acceso es restringido pueden eludir la prohibición, lo cual indicaría una alta demanda y reconocimiento de la utilidad de la aplicación. El resultado obtenido por medio del método de Diferencias en Diferencias indica un impacto negativo significativo en la probabilidad de que cada usuario-día presente un nuevo lanzamiento de software, en Italia en comparación con otros países; esto indica una menor capacidad productiva como resultado de la prohibición.

Finally, the authors analyze the impact on productivity in software development using daily user-level data provided by GitHub. They leverage the ban of ChatGPT in Italy, comparing it to France and Austria, where the application is freely accessible. As productivity measures, the authors use the existence of new releases by each user; the sum of pushes, pull requests, comments on pull requests, comments on commits, repo creations, and issues; the sum of pushes and pulls; and the total number of events by each user. They also analyze the quantity of new Tor users, as users in countries where access is restricted may bypass the ban through this means, indicating high demand and recognition of the application's utility. The result obtained through the Differences in Differences method indicates a significant negative impact on the probability that each user-day presents a new software release in Italy compared to other countries. This suggests lower productivity as a result of the prohibition.